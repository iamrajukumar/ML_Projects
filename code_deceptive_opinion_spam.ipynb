{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('deceptive-opinion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deceptive</th>\n",
       "      <th>hotel</th>\n",
       "      <th>polarity</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>truthful</td>\n",
       "      <td>conrad</td>\n",
       "      <td>positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>We stayed for a one night getaway with family ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>truthful</td>\n",
       "      <td>hyatt</td>\n",
       "      <td>positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>Triple A rate with upgrade to view room was le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>truthful</td>\n",
       "      <td>hyatt</td>\n",
       "      <td>positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>This comes a little late as I'm finally catchi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>truthful</td>\n",
       "      <td>omni</td>\n",
       "      <td>positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>The Omni Chicago really delivers on all fronts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>truthful</td>\n",
       "      <td>hyatt</td>\n",
       "      <td>positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>I asked for a high floor away from the elevato...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  deceptive   hotel  polarity       source  \\\n",
       "0  truthful  conrad  positive  TripAdvisor   \n",
       "1  truthful   hyatt  positive  TripAdvisor   \n",
       "2  truthful   hyatt  positive  TripAdvisor   \n",
       "3  truthful    omni  positive  TripAdvisor   \n",
       "4  truthful   hyatt  positive  TripAdvisor   \n",
       "\n",
       "                                                text  \n",
       "0  We stayed for a one night getaway with family ...  \n",
       "1  Triple A rate with upgrade to view room was le...  \n",
       "2  This comes a little late as I'm finally catchi...  \n",
       "3  The Omni Chicago really delivers on all fronts...  \n",
       "4  I asked for a high floor away from the elevato...  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['complete_text']=dataset['source'] + '' +dataset['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deceptive</th>\n",
       "      <th>hotel</th>\n",
       "      <th>polarity</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>complete_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>truthful</td>\n",
       "      <td>conrad</td>\n",
       "      <td>positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>We stayed for a one night getaway with family ...</td>\n",
       "      <td>TripAdvisorWe stayed for a one night getaway w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>truthful</td>\n",
       "      <td>hyatt</td>\n",
       "      <td>positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>Triple A rate with upgrade to view room was le...</td>\n",
       "      <td>TripAdvisorTriple A rate with upgrade to view ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>truthful</td>\n",
       "      <td>hyatt</td>\n",
       "      <td>positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>This comes a little late as I'm finally catchi...</td>\n",
       "      <td>TripAdvisorThis comes a little late as I'm fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>truthful</td>\n",
       "      <td>omni</td>\n",
       "      <td>positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>The Omni Chicago really delivers on all fronts...</td>\n",
       "      <td>TripAdvisorThe Omni Chicago really delivers on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>truthful</td>\n",
       "      <td>hyatt</td>\n",
       "      <td>positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>I asked for a high floor away from the elevato...</td>\n",
       "      <td>TripAdvisorI asked for a high floor away from ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  deceptive   hotel  polarity       source  \\\n",
       "0  truthful  conrad  positive  TripAdvisor   \n",
       "1  truthful   hyatt  positive  TripAdvisor   \n",
       "2  truthful   hyatt  positive  TripAdvisor   \n",
       "3  truthful    omni  positive  TripAdvisor   \n",
       "4  truthful   hyatt  positive  TripAdvisor   \n",
       "\n",
       "                                                text  \\\n",
       "0  We stayed for a one night getaway with family ...   \n",
       "1  Triple A rate with upgrade to view room was le...   \n",
       "2  This comes a little late as I'm finally catchi...   \n",
       "3  The Omni Chicago really delivers on all fronts...   \n",
       "4  I asked for a high floor away from the elevato...   \n",
       "\n",
       "                                       complete_text  \n",
       "0  TripAdvisorWe stayed for a one night getaway w...  \n",
       "1  TripAdvisorTriple A rate with upgrade to view ...  \n",
       "2  TripAdvisorThis comes a little late as I'm fin...  \n",
       "3  TripAdvisorThe Omni Chicago really delivers on...  \n",
       "4  TripAdvisorI asked for a high floor away from ...  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deceptive    800\n",
       "truthful     800\n",
       "Name: deceptive, dtype: int64"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['deceptive'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data=dataset['deceptive'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data=le.fit_transform(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       TripAdvisorWe stayed for a one night getaway w...\n",
      "1       TripAdvisorTriple A rate with upgrade to view ...\n",
      "2       TripAdvisorThis comes a little late as I'm fin...\n",
      "3       TripAdvisorThe Omni Chicago really delivers on...\n",
      "4       TripAdvisorI asked for a high floor away from ...\n",
      "                              ...                        \n",
      "1595    MTurkProblems started when I booked the InterC...\n",
      "1596    MTurkThe Amalfi Hotel has a beautiful website ...\n",
      "1597    MTurkThe Intercontinental Chicago Magnificent ...\n",
      "1598    MTurkThe Palmer House Hilton, while it looks g...\n",
      "1599    MTurkAs a former Chicagoan, I'm appalled at th...\n",
      "Name: complete_text, Length: 1600, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataset['complete_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## removing stopwords and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw=set(stopwords.words('english'))\n",
    "ps=PorterStemmer()\n",
    "\n",
    "def cleantext(sample):\n",
    "    sample=sample.lower()\n",
    "    sample=sample.replace(\"<br /><br />\",\" \")\n",
    "    sample=re.sub(\"[^a-zA-Z]+\",\" \",sample)\n",
    "    \n",
    "    sample=sample.split(\" \")\n",
    "    sample=[ps.stem(s) for s in sample if s not in sw] # stemming and removing stopwords\n",
    "    \n",
    "    sample=\" \".join(sample)\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tripadvisorw stay one night getaway famili thursday tripl aaa rate steal th floor room complet plasma tv bose stereo voss evian water gorgeou bathroom tub fine us concierg help cannot beat locat flaw breakfast pricey servic slow hour four kid four adult friday morn even though two tabl restaur food good worth wait would return heartbeat gem chicago '"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleantext(dataset['complete_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TripAdvisorWe stayed for a one night getaway with family on a thursday. Triple AAA rate of 173 was a steal. 7th floor room complete with 44in plasma TV bose stereo, voss and evian water, and gorgeous bathroom(no tub but was fine for us) Concierge was very helpful. You cannot beat this location... Only flaw was breakfast was pricey and service was very very slow(2hours for four kids and four adults on a friday morning) even though there were only two other tables in the restaurant. Food was very good so it was worth the wait. I would return in a heartbeat. A gem in chicago... \\n'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['complete_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply clean text function to each sms\n",
    "\n",
    "dataset['cleanedmessage']=dataset['complete_text'].apply(cleantext)\n",
    "corpus=dataset['cleanedmessage'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vectorization/Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "\n",
    "\n",
    "#CountVectorizer transformer from the sklearn.feature_extraction model has its own internal tokenization\n",
    "#and normalization methods\n",
    "\n",
    "cv=CountVectorizer(max_df=0.5,max_features=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 6626)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data=cv.fit_transform(corpus)\n",
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5955)\t1\n",
      "  (0, 3925)\t1\n",
      "  (0, 3794)\t1\n",
      "  (0, 2339)\t1\n",
      "  (0, 2012)\t1\n",
      "  (0, 5777)\t1\n",
      "  (0, 5962)\t1\n",
      "  (0, 0)\t1\n",
      "  (0, 4500)\t1\n",
      "  (0, 5400)\t1\n",
      "  (0, 5710)\t1\n",
      "  (0, 2146)\t1\n",
      "  (0, 1096)\t1\n",
      "  (0, 4215)\t1\n",
      "  (0, 5993)\t1\n",
      "  (0, 648)\t1\n",
      "  (0, 5412)\t1\n",
      "  (0, 6276)\t1\n",
      "  (0, 1914)\t1\n",
      "  (0, 6331)\t1\n",
      "  (0, 2399)\t1\n",
      "  (0, 474)\t1\n",
      "  (0, 5979)\t1\n",
      "  (0, 2091)\t1\n",
      "  (0, 6178)\t1\n",
      "  :\t:\n",
      "  (0, 3231)\t1\n",
      "  (0, 2127)\t1\n",
      "  (0, 675)\t1\n",
      "  (0, 4341)\t1\n",
      "  (0, 4985)\t1\n",
      "  (0, 5176)\t1\n",
      "  (0, 2698)\t1\n",
      "  (0, 2209)\t2\n",
      "  (0, 3032)\t1\n",
      "  (0, 83)\t1\n",
      "  (0, 2242)\t1\n",
      "  (0, 3571)\t1\n",
      "  (0, 1901)\t1\n",
      "  (0, 5750)\t1\n",
      "  (0, 6002)\t1\n",
      "  (0, 5624)\t1\n",
      "  (0, 4690)\t1\n",
      "  (0, 2168)\t1\n",
      "  (0, 2393)\t1\n",
      "  (0, 6564)\t1\n",
      "  (0, 6289)\t1\n",
      "  (0, 6568)\t1\n",
      "  (0, 4710)\t1\n",
      "  (0, 2583)\t1\n",
      "  (0, 2322)\t1\n"
     ]
    }
   ],
   "source": [
    "print(x_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign weights to every word in the vocab using tf-idf\n",
    "tfidf=TfidfTransformer()\n",
    "x_data=tfidf.fit_transform(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6568)\t0.055363262366652774\n",
      "  (0, 6564)\t0.11013088271174312\n",
      "  (0, 6331)\t0.09724154918875624\n",
      "  (0, 6289)\t0.08968710720125812\n",
      "  (0, 6276)\t0.22666939262047192\n",
      "  (0, 6178)\t0.0744228949359435\n",
      "  (0, 6002)\t0.08449936439507968\n",
      "  (0, 5993)\t0.10640595871100358\n",
      "  (0, 5979)\t0.1263540228293414\n",
      "  (0, 5962)\t0.2062256171099869\n",
      "  (0, 5955)\t0.1167832931260105\n",
      "  (0, 5777)\t0.18230793301639647\n",
      "  (0, 5750)\t0.09972472197072822\n",
      "  (0, 5710)\t0.10984864004551063\n",
      "  (0, 5624)\t0.14398670716838205\n",
      "  (0, 5412)\t0.1942667750631917\n",
      "  (0, 5400)\t0.18230793301639647\n",
      "  (0, 5176)\t0.12586650539016983\n",
      "  (0, 4985)\t0.05829416738009816\n",
      "  (0, 4710)\t0.09529227860440036\n",
      "  (0, 4690)\t0.07958139863614036\n",
      "  (0, 4500)\t0.09742531385516666\n",
      "  (0, 4341)\t0.16026949166130355\n",
      "  (0, 4215)\t0.1618641575059115\n",
      "  (0, 3925)\t0.06254868460732095\n",
      "  :\t:\n",
      "  (0, 2698)\t0.09069678493737839\n",
      "  (0, 2604)\t0.07753980359600562\n",
      "  (0, 2583)\t0.19964419140759157\n",
      "  (0, 2399)\t0.13687384125839097\n",
      "  (0, 2393)\t0.07763388384657685\n",
      "  (0, 2339)\t0.13982571615081857\n",
      "  (0, 2322)\t0.1942667750631917\n",
      "  (0, 2242)\t0.1692764588156712\n",
      "  (0, 2209)\t0.24890103013609396\n",
      "  (0, 2168)\t0.09055041176576084\n",
      "  (0, 2146)\t0.08697932308305335\n",
      "  (0, 2127)\t0.1942667750631917\n",
      "  (0, 2091)\t0.12586650539016983\n",
      "  (0, 2012)\t0.1061570615921851\n",
      "  (0, 1914)\t0.2147105505736767\n",
      "  (0, 1901)\t0.06875116547965628\n",
      "  (0, 1118)\t0.104006739557562\n",
      "  (0, 1096)\t0.11714080215231099\n",
      "  (0, 805)\t0.1458306909265346\n",
      "  (0, 675)\t0.08982924787899656\n",
      "  (0, 648)\t0.1942667750631917\n",
      "  (0, 483)\t0.14779769523236636\n",
      "  (0, 474)\t0.07643364394779106\n",
      "  (0, 83)\t0.16724157385031138\n",
      "  (0, 0)\t0.18578184159950195\n"
     ]
    }
   ],
   "source": [
    "print(x_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 6626)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600,)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "## splitting of dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(x_data,y_data,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8791666666666667"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "clf_lr= LogisticRegression(solver='liblinear', penalty='l1')\n",
    "clf_lr.fit(X_train, y_train)\n",
    "pred_lr=clf_lr.predict(X_test)\n",
    "clf_lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87       247\n",
      "           1       0.81      0.99      0.89       233\n",
      "\n",
      "    accuracy                           0.88       480\n",
      "   macro avg       0.90      0.88      0.88       480\n",
      "weighted avg       0.90      0.88      0.88       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9229166666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf_mnb=MultinomialNB(alpha=0.2)\n",
    "\n",
    "clf_mnb.fit(X_train,y_train)\n",
    "pred_mnb=clf_mnb.predict(X_test)\n",
    "acc_mnb=clf_mnb.score(X_test,y_test)\n",
    "\n",
    "#acc=accuracy_score(y_test,pred)\n",
    "print(\"Accuracy : \",acc_mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93       247\n",
      "           1       0.94      0.90      0.92       233\n",
      "\n",
      "    accuracy                           0.92       480\n",
      "   macro avg       0.92      0.92      0.92       480\n",
      "weighted avg       0.92      0.92      0.92       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred_mnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.Sequential()\n",
    "model.add(Dense(16,activation='relu',input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",loss=\"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1120/1120 [==============================] - 0s 152us/step - loss: 0.6897 - accuracy: 0.5973\n",
      "Epoch 2/100\n",
      "1120/1120 [==============================] - 0s 77us/step - loss: 0.6642 - accuracy: 0.8411\n",
      "Epoch 3/100\n",
      "1120/1120 [==============================] - 0s 82us/step - loss: 0.6308 - accuracy: 0.9250\n",
      "Epoch 4/100\n",
      "1120/1120 [==============================] - 0s 91us/step - loss: 0.5946 - accuracy: 0.9554\n",
      "Epoch 5/100\n",
      "1120/1120 [==============================] - 0s 96us/step - loss: 0.5548 - accuracy: 0.9589\n",
      "Epoch 6/100\n",
      "1120/1120 [==============================] - 0s 90us/step - loss: 0.5131 - accuracy: 0.9696\n",
      "Epoch 7/100\n",
      "1120/1120 [==============================] - 0s 95us/step - loss: 0.4699 - accuracy: 0.9732\n",
      "Epoch 8/100\n",
      "1120/1120 [==============================] - 0s 86us/step - loss: 0.4271 - accuracy: 0.9777\n",
      "Epoch 9/100\n",
      "1120/1120 [==============================] - 0s 97us/step - loss: 0.3848 - accuracy: 0.9848\n",
      "Epoch 10/100\n",
      "1120/1120 [==============================] - 0s 87us/step - loss: 0.3437 - accuracy: 0.9875\n",
      "Epoch 11/100\n",
      "1120/1120 [==============================] - 0s 80us/step - loss: 0.3049 - accuracy: 0.9902\n",
      "Epoch 12/100\n",
      "1120/1120 [==============================] - 0s 97us/step - loss: 0.2677 - accuracy: 0.9920\n",
      "Epoch 13/100\n",
      "1120/1120 [==============================] - 0s 73us/step - loss: 0.2330 - accuracy: 0.9946\n",
      "Epoch 14/100\n",
      "1120/1120 [==============================] - 0s 102us/step - loss: 0.2010 - accuracy: 0.9955\n",
      "Epoch 15/100\n",
      "1120/1120 [==============================] - 0s 70us/step - loss: 0.1722 - accuracy: 0.9991\n",
      "Epoch 16/100\n",
      "1120/1120 [==============================] - 0s 97us/step - loss: 0.1458 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "1120/1120 [==============================] - 0s 88us/step - loss: 0.1226 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "1120/1120 [==============================] - 0s 82us/step - loss: 0.1021 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "1120/1120 [==============================] - 0s 95us/step - loss: 0.0845 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "1120/1120 [==============================] - 0s 76us/step - loss: 0.0695 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1120/1120 [==============================] - 0s 90us/step - loss: 0.0565 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "1120/1120 [==============================] - 0s 88us/step - loss: 0.0459 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "1120/1120 [==============================] - 0s 79us/step - loss: 0.0370 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1120/1120 [==============================] - 0s 85us/step - loss: 0.0298 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1120/1120 [==============================] - 0s 76us/step - loss: 0.0236 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1120/1120 [==============================] - 0s 84us/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1120/1120 [==============================] - 0s 78us/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1120/1120 [==============================] - 0s 84us/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1120/1120 [==============================] - 0s 70us/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1120/1120 [==============================] - 0s 74us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1120/1120 [==============================] - 0s 81us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1120/1120 [==============================] - 0s 59us/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1120/1120 [==============================] - 0s 94us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1120/1120 [==============================] - 0s 83us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1120/1120 [==============================] - 0s 91us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1120/1120 [==============================] - 0s 83us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1120/1120 [==============================] - 0s 104us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1120/1120 [==============================] - 0s 71us/step - loss: 7.8471e-04 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1120/1120 [==============================] - 0s 85us/step - loss: 5.8266e-04 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1120/1120 [==============================] - 0s 87us/step - loss: 4.3298e-04 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1120/1120 [==============================] - 0s 103us/step - loss: 3.1943e-04 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1120/1120 [==============================] - 0s 78us/step - loss: 2.3625e-04 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1120/1120 [==============================] - 0s 91us/step - loss: 1.7369e-04 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1120/1120 [==============================] - 0s 89us/step - loss: 1.2789e-04 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1120/1120 [==============================] - 0s 78us/step - loss: 9.3802e-05 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1120/1120 [==============================] - 0s 75us/step - loss: 6.8700e-05 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1120/1120 [==============================] - 0s 85us/step - loss: 5.0230e-05 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1120/1120 [==============================] - 0s 78us/step - loss: 3.7113e-05 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1120/1120 [==============================] - 0s 85us/step - loss: 2.7062e-05 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1120/1120 [==============================] - 0s 72us/step - loss: 1.9886e-05 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1120/1120 [==============================] - 0s 73us/step - loss: 1.4678e-05 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1120/1120 [==============================] - 0s 75us/step - loss: 1.0880e-05 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1120/1120 [==============================] - 0s 94us/step - loss: 7.9904e-06 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1120/1120 [==============================] - 0s 79us/step - loss: 5.9680e-06 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1120/1120 [==============================] - 0s 86us/step - loss: 4.4540e-06 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1120/1120 [==============================] - 0s 77us/step - loss: 3.3430e-06 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1120/1120 [==============================] - 0s 91us/step - loss: 2.5335e-06 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1120/1120 [==============================] - 0s 82us/step - loss: 1.9255e-06 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1120/1120 [==============================] - 0s 80us/step - loss: 1.4783e-06 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1120/1120 [==============================] - 0s 74us/step - loss: 1.1417e-06 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1120/1120 [==============================] - 0s 67us/step - loss: 8.9354e-07 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1120/1120 [==============================] - 0s 89us/step - loss: 7.0601e-07 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1120/1120 [==============================] - 0s 71us/step - loss: 5.6183e-07 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1120/1120 [==============================] - 0s 68us/step - loss: 4.5000e-07 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1120/1120 [==============================] - 0s 74us/step - loss: 3.6579e-07 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1120/1120 [==============================] - 0s 71us/step - loss: 2.9963e-07 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1120/1120 [==============================] - 0s 77us/step - loss: 2.4911e-07 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1120/1120 [==============================] - 0s 75us/step - loss: 2.0883e-07 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1120/1120 [==============================] - 0s 67us/step - loss: 1.7572e-07 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1120/1120 [==============================] - 0s 75us/step - loss: 1.4955e-07 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1120/1120 [==============================] - 0s 75us/step - loss: 1.2916e-07 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1120/1120 [==============================] - 0s 72us/step - loss: 1.1180e-07 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1120/1120 [==============================] - 0s 87us/step - loss: 9.7508e-08 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1120/1120 [==============================] - 0s 66us/step - loss: 8.6018e-08 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1120/1120 [==============================] - 0s 78us/step - loss: 7.6300e-08 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1120/1120 [==============================] - 0s 71us/step - loss: 6.8163e-08 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1120/1120 [==============================] - 0s 70us/step - loss: 6.1125e-08 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1120/1120 [==============================] - 0s 79us/step - loss: 5.5341e-08 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1120/1120 [==============================] - 0s 68us/step - loss: 5.0250e-08 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1120/1120 [==============================] - 0s 74us/step - loss: 4.6048e-08 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1120/1120 [==============================] - 0s 79us/step - loss: 4.2222e-08 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1120/1120 [==============================] - 0s 71us/step - loss: 3.8964e-08 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1120/1120 [==============================] - 0s 64us/step - loss: 3.6128e-08 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1120/1120 [==============================] - 0s 70us/step - loss: 3.3464e-08 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1120/1120 [==============================] - 0s 71us/step - loss: 3.1378e-08 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1120/1120 [==============================] - 0s 73us/step - loss: 2.9493e-08 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1120/1120 [==============================] - 0s 70us/step - loss: 2.7705e-08 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1120/1120 [==============================] - 0s 86us/step - loss: 2.6101e-08 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1120/1120 [==============================] - 0s 67us/step - loss: 2.4673e-08 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1120/1120 [==============================] - 0s 74us/step - loss: 2.3438e-08 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1120/1120 [==============================] - 0s 70us/step - loss: 2.2207e-08 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1120/1120 [==============================] - 0s 71us/step - loss: 2.1143e-08 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1120/1120 [==============================] - 0s 69us/step - loss: 2.0215e-08 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1120/1120 [==============================] - 0s 72us/step - loss: 1.9378e-08 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1120/1120 [==============================] - 0s 73us/step - loss: 1.8493e-08 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1120/1120 [==============================] - 0s 72us/step - loss: 1.7755e-08 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1120/1120 [==============================] - 0s 54us/step - loss: 1.7012e-08 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1120/1120 [==============================] - 0s 71us/step - loss: 1.6382e-08 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1120/1120 [==============================] - 0s 65us/step - loss: 1.5749e-08 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1120/1120 [==============================] - 0s 65us/step - loss: 1.5149e-08 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(X_train,y_train,batch_size=128,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "pred_mlp=model.predict(X_test)\n",
    "pred_mlp[pred_mlp>=0.5]=1\n",
    "pred_mlp[pred_mlp<0.5]=0\n",
    "print(pred_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9125\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_mlp=accuracy_score(pred_mlp,y_test)\n",
    "print(acc_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9125\n"
     ]
    }
   ],
   "source": [
    "acc_mlp=accuracy_score(pred_mlp,y_test)\n",
    "print(acc_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91       247\n",
      "           1       0.91      0.91      0.91       233\n",
      "\n",
      "    accuracy                           0.91       480\n",
      "   macro avg       0.91      0.91      0.91       480\n",
      "weighted avg       0.91      0.91      0.91       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO CALCULATE TRUE POSITIVE, TRUE NEGATIVE ,FALSE POSITIVE AND FALSE NEGATIVE \n",
    "\n",
    "def perf_measure(y_actual, y_hat):\n",
    "    y_actual=np.array(y_actual)\n",
    "    y_hat=np.array(y_hat)\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i] and y_hat[i]==1:\n",
    "           TP += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "           TN += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers=[]\n",
    "\n",
    "classifiers.append(('LogisticRegression',clf_lr))\n",
    "classifiers.append(('MNB',clf_mnb))\n",
    "#classifiers.append(('LSTM',model1))\n",
    "classifiers.append(('MLP',model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "result=[]\n",
    "cnf_matric_parameter=[]\n",
    "for i,v in classifiers:\n",
    "    if i=='MLP':\n",
    "        pred=v.predict(X_test)\n",
    "        pred[pred>=0.5]=1\n",
    "        pred[pred<0.5]=0\n",
    "        print(pred)\n",
    "        acc=accuracy_score(y_test,pred)\n",
    "        precision = precision_score(y_test,pred)\n",
    "        recall=recall_score(y_test, pred)\n",
    "        f_measure=f1_score(y_test,pred)\n",
    "        result.append((i,acc,precision,recall,f_measure))\n",
    "        \n",
    "        TP,FP,TN,FN=perf_measure(y_test,pred)\n",
    "        cnf_matric_parameter.append((i,TP,FP,TN,FN))\n",
    "        continue\n",
    "        \n",
    "    \n",
    "    pred=v.predict(X_test)\n",
    "    acc=accuracy_score(y_test,pred)\n",
    "    precision = precision_score(y_test,pred)\n",
    "    recall=recall_score(y_test, pred)\n",
    "    #print(precision)\n",
    "    f_measure=f1_score(y_test,pred)\n",
    "    result.append((i,acc,precision,recall,f_measure))\n",
    "    \n",
    "    TP,FP,TN,FN=perf_measure(y_test,pred)\n",
    "    cnf_matric_parameter.append((i,TP,FP,TN,FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Algorithm  Accuracy  Precision    Recall  F-measure\n",
      "0  LogisticRegression  0.879167   0.807018  0.987124   0.888031\n",
      "1                 MNB  0.922917   0.937500  0.901288   0.919037\n",
      "2                 MLP  0.912500   0.906383  0.914163   0.910256\n"
     ]
    }
   ],
   "source": [
    "column_names=['Algorithm','Accuracy','Precision','Recall','F-measure']\n",
    "df1=pd.DataFrame(result,columns=column_names)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f912537ac90>"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1.plot(kind='bar', ylim=(0.65,1.0), figsize=(15,6), align='center', colormap=\"Accent\")\n",
    "plt.xticks(np.arange(3), df1['Algorithm'],fontsize=15,color='C2')\n",
    "plt.ylabel('Score',fontsize=20,color='C2')\n",
    "plt.title('Distribution by Classifier',fontsize=20,color='C2')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.,fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset['complete_text']\n",
    "Y=dataset['deceptive']\n",
    "\n",
    "le = LabelEncoder()\n",
    "Y=le.fit_transform(Y)\n",
    "Y=Y.reshape(-1,1)\n",
    "\n",
    "# split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "max_len = 150\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X_train)\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 150, 50)           50000     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 96,337\n",
      "Trainable params: 96,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = LSTM_model()\n",
    "model1.summary()\n",
    "model1.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raju/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1088 samples, validate on 272 samples\n",
      "Epoch 1/10\n",
      "1088/1088 [==============================] - 3s 3ms/step - loss: 0.6911 - accuracy: 0.5349 - val_loss: 0.6842 - val_accuracy: 0.6029\n",
      "Epoch 2/10\n",
      "1088/1088 [==============================] - 2s 2ms/step - loss: 0.6610 - accuracy: 0.6903 - val_loss: 0.6224 - val_accuracy: 0.6801\n",
      "Epoch 3/10\n",
      "1088/1088 [==============================] - 2s 2ms/step - loss: 0.5053 - accuracy: 0.7904 - val_loss: 0.5367 - val_accuracy: 0.7463\n",
      "Epoch 4/10\n",
      "1088/1088 [==============================] - 2s 2ms/step - loss: 0.4504 - accuracy: 0.8162 - val_loss: 0.5169 - val_accuracy: 0.7574\n",
      "Epoch 5/10\n",
      "1088/1088 [==============================] - 2s 2ms/step - loss: 0.5130 - accuracy: 0.7978 - val_loss: 0.5043 - val_accuracy: 0.7426\n",
      "Epoch 6/10\n",
      "1088/1088 [==============================] - 2s 2ms/step - loss: 0.2966 - accuracy: 0.9007 - val_loss: 0.5212 - val_accuracy: 0.7463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f912474b9d0>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(sequences_matrix,Y_train,batch_size=128,epochs=10,\n",
    "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tok.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "accr = model1.evaluate(test_sequences_matrix,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set\n",
      "  Loss: 0.468\n",
      "  Accuracy: 0.796\n"
     ]
    }
   ],
   "source": [
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'MTurkHow should I start? Well, after staying at the Ambassador East Hotel, i realized it was my favorite hotel ever. The rooms are amazing. The food is great. The Pump room bar is awesome. I love this hotel. If your ever in Chicago, the Ambassador East Hotel is the place to go.\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-205-45fdd9ce4920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \"\"\"\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    263\u001b[0m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"M8[ns]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/arrays/numpy_.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0m_HANDLED_TYPES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'MTurkHow should I start? Well, after staying at the Ambassador East Hotel, i realized it was my favorite hotel ever. The rooms are amazing. The food is great. The Pump room bar is awesome. I love this hotel. If your ever in Chicago, the Ambassador East Hotel is the place to go.\\n'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
